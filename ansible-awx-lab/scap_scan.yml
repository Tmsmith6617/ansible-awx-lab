---
- name: Run SCAP Scan and Upload Report to S3
  hosts: all
  become: yes
  
  vars:
    # Remote paths (unchanged)
    report_filename: "report_{{ inventory_hostname }}.html"
    remote_report_path: "/tmp/scap/{{ report_filename }}"
    
    # EE temporary paths (unchanged)
    ee_temp_fetch_path: "/tmp/scap_ee_fetch"
    fetch_source_path: "{{ ee_temp_fetch_path }}/{{ inventory_hostname }}/tmp/scap/{{ report_filename }}"
    
    # S3 paths
    s3_bucket_name: "your-scap-reports-bucket"
    s3_object_key: "scap-reports/{{ inventory_hostname }}/{{ report_filename }}"
    s3_region: "us-east-1" # Set your AWS region
    
  tasks:
    # --- SCANNING AND FETCHING (UNCHANGED) ---

    - name: Ensure scap-security-guide package is installed
      ansible.builtin.dnf:
        name: scap-security-guide
        state: present

    - name: Ensure /tmp/scap directory exists
      ansible.builtin.file:
        path: /tmp/scap
        state: directory
        mode: '0755'

    - name: Run SCAP scan using STIG profile and save report locally
      ansible.builtin.shell: |
        oscap xccdf eval \
        --profile xccdf_org.ssgproject.content_profile_stig \
        --results /tmp/scap/results_{{ inventory_hostname }}.xml \
        --report /tmp/scap/report_{{ inventory_hostname }}.html \
        /usr/share/xml/scap/ssg/content/ssg-rhel10-ds.xml
      failed_when: false
      changed_when: true

    - name: Fetch report from remote host to EE temp directory
      ansible.builtin.fetch:
        src: "{{ remote_report_path }}"
        dest: "{{ ee_temp_fetch_path }}"
        flat: false

    # --- S3 UPLOAD (NEW WORKAROUND) ---
    
    # This task uploads the file fetched to the Execution Environment onto S3.
    - name: Upload SCAP report to S3 bucket
      amazon.aws.s3_object:
        mode: put
        bucket: "{{ s3_bucket_name }}"
        object: "{{ s3_object_key }}"
        src: "{{ fetch_source_path }}"
        region: "{{ s3_region }}"
        permission: public-read # Makes the file publicly accessible via URL
      delegate_to: localhost
      run_once: true
      register: s3_upload_result

    # This task retrieves the public URL for the file we just uploaded.
    - name: Get public URL for S3 object
      amazon.aws.s3_object:
        mode: geturl
        bucket: "{{ s3_bucket_name }}"
        object: "{{ s3_object_key }}"
        region: "{{ s3_region }}"
        expiration: 0 # Get permanent URL
      delegate_to: localhost
      run_once: true
      register: s3_url_result
      when: s3_upload_result is changed # Only get URL if upload succeeded

    # This task prints the URL to the job output, making it clickable.
    - name: Print Public Report URL to Job Output
      ansible.builtin.debug:
        msg: "SCAP Report is now available at: {{ s3_url_result.url }}"
      when: s3_url_result is defined and s3_url_result.url is defined

    # --- CLEANUP (UNCHANGED) ---
    
    - name: Cleanup /tmp/scap directory on remote host
      ansible.builtin.file:
        path: /tmp/scap
        state: absent
      when: not ansible_failed_result is defined or ansible_failed_result.ansible_module != 'fetch'
